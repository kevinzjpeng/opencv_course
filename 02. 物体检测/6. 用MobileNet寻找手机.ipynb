{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 62, 'confidence': 0.9213576316833496, 'bbox': [0.07901328802108765, 0.16707581281661987, 0.6022751331329346, 0.9849607348442078]}, {'label': 62, 'confidence': 0.36658975481987, 'bbox': [0.055794745683670044, 0.4926317632198334, 0.5795766115188599, 0.9740325212478638]}]]\n"
     ]
    }
   ],
   "source": [
    "detections = model(camera.value)\n",
    "\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 62, 'confidence': 0.9213576316833496, 'bbox': [0.07901328802108765, 0.16707581281661987, 0.6022751331329346, 0.9849607348442078]}\n"
     ]
    }
   ],
   "source": [
    "image_number = 0\n",
    "object_number = 0\n",
    "\n",
    "print(detections[image_number][object_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=1, description='tracked label')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    image_widget,\n",
    "    label_widget\n",
    "]))\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "        \n",
    "def execute(change):\n",
    "    image = change['new']\n",
    "    \n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    " \n",
    "    # select detections that match selected class label\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == 77] ## is cell phone\n",
    "    \n",
    "    if len(matching_detections)>0:\n",
    "        print(matching_detections)\n",
    "    # get detection closest to center of field of view and draw it\n",
    "    det = closest_detection(matching_detections)\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (0, 255, 0), 5)\n",
    "    \n",
    "    # update image widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr8_to_jpeg(value, quality=10):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ef68c57283482cb3320138be4d19c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=1, description='tracked label')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    image_widget,\n",
    "    label_widget\n",
    "]))\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "        \n",
    "def execute(change):\n",
    "    image = change['new']\n",
    "    \n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    " \n",
    "    # select detections that match selected class label\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == 77] ## is cell phone\n",
    "    \n",
    "    if len(matching_detections)>0:\n",
    "        print(matching_detections)\n",
    "    # get detection closest to center of field of view and draw it\n",
    "    det = closest_detection(matching_detections)\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), (0, 255, 0), 5)\n",
    "    \n",
    "    # update image widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
