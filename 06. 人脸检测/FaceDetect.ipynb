{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import atexit\n",
    "import threading\n",
    "import enum\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=10):\n",
    "    confi = 0.5\n",
    "    image = value.copy()\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > confi:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the\n",
    "            # object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # draw the bounding box of the face along with the associated\n",
    "            # probability\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
    "            cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)\n",
    "\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    value = traitlets.Any()\n",
    "    \n",
    "    # config\n",
    "    width = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    height = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    fps = traitlets.Integer(default_value=21).tag(config=True)\n",
    "    capture_width = traitlets.Integer(default_value=3280).tag(config=True)\n",
    "    capture_height = traitlets.Integer(default_value=2464).tag(config=True)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.value = np.empty((self.height, self.width, 2), dtype=np.uint8)\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            re, image = self.cap.read()\n",
    "\n",
    "            if not re:\n",
    "                raise RuntimeError('Could not read image from camera.')\n",
    "\n",
    "            self.value = image\n",
    "            self.start()\n",
    "        except:\n",
    "            self.stop()\n",
    "            raise RuntimeError(\n",
    "                'Could not initialize camera.  Please see error trace.')\n",
    "\n",
    "        atexit.register(self.stop)\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while True:\n",
    "            re, image = self.cap.read()\n",
    "            if re:\n",
    "                self.value = image\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    def _gst_str(self):\n",
    "        return 'nvarguscamerasrc ! video/x-raw(memory:NVMM), width=%d, height=%d, format=(string)NV12, framerate=(fraction)%d/1 ! nvvidconv ! video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! videoconvert ! appsink' % (\n",
    "                self.capture_width, self.capture_height, self.fps, self.width, self.height)\n",
    "    \n",
    "    def start(self):\n",
    "        if not self.cap.isOpened():\n",
    "            self.cap.open(self._gst_str(), cv2.CAP_GSTREAMER)\n",
    "        if not hasattr(self, 'thread') or not self.thread.isAlive():\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if hasattr(self, 'cap'):\n",
    "            self.cap.release()\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "            \n",
    "    def restart(self):\n",
    "        self.stop()\n",
    "        self.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a58aea6e0f45fe92834d72928a2d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "camera = Camera.instance(width=500, height=500)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=500, height=500)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
